{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1764618046466,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "cQJXqAqNxg_5",
    "outputId": "d96f819b-fabb-4e17-9574-0b9fca4bb78f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1764618047842,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "wyugczFF6wjL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1764618049577,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "rp1a9_Hj60lA"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"/content/drive/MyDrive/voice_project\"\n",
    "STATS_PATH = os.path.join(PROJECT_PATH, \"scaling_stats\")\n",
    "\n",
    "# Model Paths\n",
    "# Model A: Baseline (10k) - Used for GENDER and AGE baseline\n",
    "MODEL_A_PATH = os.path.join(PROJECT_PATH, \"best_voice_model.pth\")\n",
    "\n",
    "# Model B: Big Data (55k) - Used for AGE\n",
    "MODEL_B_PATH = os.path.join(PROJECT_PATH, \"best_age_model_50plus.pth\")\n",
    "\n",
    "# Model C: Augmented (10k) - Used for AGE\n",
    "MODEL_C_PATH = os.path.join(PROJECT_PATH, \"First_model_building.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1764618051370,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "jVE2uc8E6-Ls"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 5\n",
    "N_MELS = 128\n",
    "FIXED_LENGTH = SAMPLE_RATE * DURATION\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1764618052758,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "RtMoRAnb6_8P"
   },
   "outputs": [],
   "source": [
    "# Old System (6 Classes) - Used by Model A & C\n",
    "AGE_MAP_6 = ['Teens', 'Twenties', 'Thirties', 'Fourties', 'Fifties', '60 Plus']\n",
    "# New System (5 Classes) - Used by Model B (and for final display)\n",
    "AGE_MAP_5 = ['Teens', 'Twenties', 'Thirties', 'Fourties', '50 Plus']\n",
    "GENDER_MAP = ['Female', 'Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1764618053890,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "xRmjWCxR7GDC",
    "outputId": "4fbf44b1-2dd0-4f1c-9b7b-d742c6225751"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1764618055455,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "dF_DA-3u7Jje",
    "outputId": "c4c58652-93c6-42dc-e263-f64f2e47c528"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    GLOBAL_MEAN = np.load(os.path.join(STATS_PATH, \"global_mean.npy\"))\n",
    "    GLOBAL_STD = np.load(os.path.join(STATS_PATH, \"global_std.npy\"))\n",
    "    print(f\"Stats Loaded: Mean={GLOBAL_MEAN:.2f}, Std={GLOBAL_STD:.2f}\")\n",
    "except:\n",
    "    print(\"Stats not found. Using defaults.\")\n",
    "    GLOBAL_MEAN, GLOBAL_STD = -59.25, 11.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1764618057749,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "8a0sjnAH7NmM"
   },
   "outputs": [],
   "source": [
    "# Architecture for Model A & C (Old 6-class system)\n",
    "class VoiceCNN_Old(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VoiceCNN_Old, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1); self.bn1 = nn.BatchNorm2d(16); self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1); self.bn2 = nn.BatchNorm2d(32); self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1); self.bn3 = nn.BatchNorm2d(64); self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_shared = nn.Linear(64 * 16 * 27, 128); self.fc_bn = nn.BatchNorm1d(128); self.dropout = nn.Dropout(0.5)\n",
    "        self.age_head = nn.Linear(128, 6)\n",
    "        self.gender_head = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(F.relu(self.fc_bn(self.fc_shared(x))))\n",
    "        return self.age_head(x), self.gender_head(x)\n",
    "\n",
    "# Architecture for Model B (New 5-class system)\n",
    "class AgeCNN_New(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AgeCNN_New, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1); self.bn1 = nn.BatchNorm2d(32); self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1); self.bn2 = nn.BatchNorm2d(64); self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1); self.bn3 = nn.BatchNorm2d(128); self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 16 * 27, 512); self.bn4 = nn.BatchNorm1d(512); self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(F.relu(self.bn4(self.fc1(x))))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1764618061304,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "mX7lnCWf7hYJ",
    "outputId": "f7b428e9-a330-45a9-9f6a-e7294f1b873c"
   },
   "outputs": [],
   "source": [
    "model_a = VoiceCNN_Old().to(device)\n",
    "if os.path.exists(MODEL_A_PATH):\n",
    "    model_a.load_state_dict(torch.load(MODEL_A_PATH, map_location=device))\n",
    "    model_a.eval()\n",
    "    print(\"Model A (Baseline) Loaded\")\n",
    "else: print(\"Model A NOT FOUND\")\n",
    "\n",
    "model_b = AgeCNN_New().to(device)\n",
    "if os.path.exists(MODEL_B_PATH):\n",
    "    model_b.load_state_dict(torch.load(MODEL_B_PATH, map_location=device))\n",
    "    model_b.eval()\n",
    "    print(\"Model B (Big Data) Loaded\")\n",
    "else: print(\"Model B NOT FOUND\")\n",
    "\n",
    "model_c = VoiceCNN_Old().to(device)\n",
    "if os.path.exists(MODEL_C_PATH):\n",
    "    model_c.load_state_dict(torch.load(MODEL_C_PATH, map_location=device))\n",
    "    model_c.eval()\n",
    "    print(\"Model C (Augmented) Loaded\")\n",
    "else: print(\"Model C NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1764618062732,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "uKsrSDlm7log"
   },
   "outputs": [],
   "source": [
    "# --- 5. Updated Prediction Logic (Full Confidence Breakdown) ---\n",
    "def predict_all():\n",
    "    print(\"\\nðŸ“‚ Click below to upload your voice clip (MP3/WAV)...\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # Define labels locally to ensure they exist\n",
    "    AGE_LABELS_LIST = ['Teens', 'Twenties', 'Thirties', 'Fourties', '50 Plus']\n",
    "    GENDER_LABELS_LIST = ['Female', 'Male']\n",
    "\n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\n Processing {filename}...\")\n",
    "        try:\n",
    "            # 1. Process Audio\n",
    "            audio, sr = librosa.load(filename, sr=SAMPLE_RATE, duration=DURATION)\n",
    "            if len(audio) < FIXED_LENGTH:\n",
    "                audio = np.pad(audio, (0, FIXED_LENGTH - len(audio)), 'constant')\n",
    "            else:\n",
    "                audio = audio[:FIXED_LENGTH]\n",
    "\n",
    "            spec = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "            log_spec = librosa.power_to_db(spec, ref=np.max)\n",
    "            norm_spec = (log_spec - GLOBAL_MEAN) / GLOBAL_STD\n",
    "\n",
    "            tensor = torch.tensor(norm_spec, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "            # 2. Run Inference\n",
    "            with torch.no_grad():\n",
    "                # Model A\n",
    "                age_logits_a, gender_logits_a = model_a(tensor)\n",
    "                # Model B\n",
    "                age_logits_b = model_b(tensor)\n",
    "                # Model C\n",
    "                age_logits_c, _ = model_c(tensor)\n",
    "\n",
    "            # 3. Decode Results\n",
    "\n",
    "            # -- Gender (From Model A) --\n",
    "            g_probs = torch.softmax(gender_logits_a, dim=1).cpu().numpy()[0]\n",
    "            gender_idx = np.argmax(g_probs)\n",
    "            gender_pred = GENDER_LABELS_LIST[gender_idx]\n",
    "            gender_conf = g_probs[gender_idx] * 100\n",
    "\n",
    "            # -- Age Processing Helper --\n",
    "            def get_age_distribution(logits, is_old_arch=False):\n",
    "                probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "                if is_old_arch:\n",
    "                    # Map 6 -> 5 classes (Sum 50s + 60s)\n",
    "                    p_50plus = probs[4] + probs[5]\n",
    "                    probs_5 = np.array([probs[0], probs[1], probs[2], probs[3], p_50plus])\n",
    "                else:\n",
    "                    probs_5 = probs\n",
    "                return probs_5 * 100 # Return array of percentages\n",
    "\n",
    "            # Get full distributions\n",
    "            dist_a = get_age_distribution(age_logits_a, is_old_arch=True)\n",
    "            dist_b = get_age_distribution(age_logits_b, is_old_arch=False)\n",
    "            dist_c = get_age_distribution(age_logits_c, is_old_arch=True)\n",
    "\n",
    "            # 4. Print Report\n",
    "            print(\"\\n\" + \"=\"*40)\n",
    "            print(f\"VOICE ANALYSIS REPORT\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Gender Section\n",
    "            bar_len = int(gender_conf / 5)\n",
    "            g_bar = \"|\" + \"â–ˆ\" * bar_len + \" \" * (20 - bar_len) + \"|\"\n",
    "            print(f\"GENDER DETECTION (Model A)\")\n",
    "            print(f\"   Result: {gender_pred.upper()}\")\n",
    "            print(f\"   Confidence: {g_bar} {gender_conf:.1f}%\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            # Age Section\n",
    "            print(f\"AGE CONFIDENCE BREAKDOWN\")\n",
    "\n",
    "            def print_model_stats(name, distribution):\n",
    "                print(f\"\\n{name}\")\n",
    "                # Find Winner\n",
    "                winner_idx = np.argmax(distribution)\n",
    "                print(f\"   Winner: {AGE_LABELS_LIST[winner_idx].upper()} ({distribution[winner_idx]:.1f}%)\")\n",
    "\n",
    "                # Print Bars\n",
    "                for i, prob in enumerate(distribution):\n",
    "                    bar_len = int(prob / 5)\n",
    "                    bar = \"|\" + \"â–ˆ\" * bar_len + \" \" * (20 - bar_len) + \"|\"\n",
    "                    print(f\"   {AGE_LABELS_LIST[i]:<10} {bar} {prob:.1f}%\")\n",
    "\n",
    "            print_model_stats(\"1. Model A (Baseline)\", dist_a)\n",
    "            print_model_stats(\"2. Model B (Big Data - Recommended)\", dist_b)\n",
    "            print_model_stats(\"3. Model C (Augmented)\", dist_c)\n",
    "\n",
    "            print(\"=\"*40)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "executionInfo": {
     "elapsed": 7692,
     "status": "ok",
     "timestamp": 1764618076864,
     "user": {
      "displayName": "Vamsi R",
      "userId": "00102015489704140573"
     },
     "user_tz": 360
    },
    "id": "uK-DIfhI700p",
    "outputId": "95853ea0-282e-4386-d4a2-b9d5daa9a27e"
   },
   "outputs": [],
   "source": [
    "predict_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM91N48WPG90mNxA3r+YclI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM91N48WPG90mNxA3r+YclI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQJXqAqNxg_5","executionInfo":{"status":"ok","timestamp":1764618046466,"user_tz":360,"elapsed":388,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}},"outputId":"d96f819b-fabb-4e17-9574-0b9fca4bb78f"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import librosa\n","import os\n","from google.colab import files"],"metadata":{"id":"wyugczFF6wjL","executionInfo":{"status":"ok","timestamp":1764618047842,"user_tz":360,"elapsed":11,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["PROJECT_PATH = \"/content/drive/MyDrive/voice_project\"\n","STATS_PATH = os.path.join(PROJECT_PATH, \"scaling_stats\")\n","\n","# Model Paths\n","# Model A: Baseline (10k) - Used for GENDER and AGE baseline\n","MODEL_A_PATH = os.path.join(PROJECT_PATH, \"best_voice_model.pth\")\n","\n","# Model B: Big Data (55k) - Used for AGE\n","MODEL_B_PATH = os.path.join(PROJECT_PATH, \"best_age_model_50plus.pth\")\n","\n","# Model C: Augmented (10k) - Used for AGE\n","MODEL_C_PATH = os.path.join(PROJECT_PATH, \"First_model_building.pth\")"],"metadata":{"id":"rp1a9_Hj60lA","executionInfo":{"status":"ok","timestamp":1764618049577,"user_tz":360,"elapsed":6,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["SAMPLE_RATE = 22050\n","DURATION = 5\n","N_MELS = 128\n","FIXED_LENGTH = SAMPLE_RATE * DURATION\n","N_FFT = 2048\n","HOP_LENGTH = 512"],"metadata":{"id":"jVE2uc8E6-Ls","executionInfo":{"status":"ok","timestamp":1764618051370,"user_tz":360,"elapsed":5,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Old System (6 Classes) - Used by Model A & C\n","AGE_MAP_6 = ['Teens', 'Twenties', 'Thirties', 'Fourties', 'Fifties', '60 Plus']\n","# New System (5 Classes) - Used by Model B (and for final display)\n","AGE_MAP_5 = ['Teens', 'Twenties', 'Thirties', 'Fourties', '50 Plus']\n","GENDER_MAP = ['Female', 'Male']"],"metadata":{"id":"RtMoRAnb6_8P","executionInfo":{"status":"ok","timestamp":1764618052758,"user_tz":360,"elapsed":16,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRmjWCxR7GDC","executionInfo":{"status":"ok","timestamp":1764618053890,"user_tz":360,"elapsed":9,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}},"outputId":"4fbf44b1-2dd0-4f1c-9b7b-d742c6225751"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"code","source":["try:\n","    GLOBAL_MEAN = np.load(os.path.join(STATS_PATH, \"global_mean.npy\"))\n","    GLOBAL_STD = np.load(os.path.join(STATS_PATH, \"global_std.npy\"))\n","    print(f\"Stats Loaded: Mean={GLOBAL_MEAN:.2f}, Std={GLOBAL_STD:.2f}\")\n","except:\n","    print(\"Stats not found. Using defaults.\")\n","    GLOBAL_MEAN, GLOBAL_STD = -59.25, 11.95"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dF_DA-3u7Jje","executionInfo":{"status":"ok","timestamp":1764618055455,"user_tz":360,"elapsed":15,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}},"outputId":"c4c58652-93c6-42dc-e263-f64f2e47c528"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Stats Loaded: Mean=-59.25, Std=11.95\n"]}]},{"cell_type":"code","source":["# Architecture for Model A & C (Old 6-class system)\n","class VoiceCNN_Old(nn.Module):\n","    def __init__(self):\n","        super(VoiceCNN_Old, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1); self.bn1 = nn.BatchNorm2d(16); self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1); self.bn2 = nn.BatchNorm2d(32); self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(32, 64, 3, padding=1); self.bn3 = nn.BatchNorm2d(64); self.pool3 = nn.MaxPool2d(2, 2)\n","        self.flatten = nn.Flatten()\n","        self.fc_shared = nn.Linear(64 * 16 * 27, 128); self.fc_bn = nn.BatchNorm1d(128); self.dropout = nn.Dropout(0.5)\n","        self.age_head = nn.Linear(128, 6)\n","        self.gender_head = nn.Linear(128, 2)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n","        x = self.flatten(x)\n","        x = self.dropout(F.relu(self.fc_bn(self.fc_shared(x))))\n","        return self.age_head(x), self.gender_head(x)\n","\n","# Architecture for Model B (New 5-class system)\n","class AgeCNN_New(nn.Module):\n","    def __init__(self):\n","        super(AgeCNN_New, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1); self.bn1 = nn.BatchNorm2d(32); self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1); self.bn2 = nn.BatchNorm2d(64); self.pool2 = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1); self.bn3 = nn.BatchNorm2d(128); self.pool3 = nn.MaxPool2d(2, 2)\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(128 * 16 * 27, 512); self.bn4 = nn.BatchNorm1d(512); self.dropout = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(512, 5)\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n","        x = self.flatten(x)\n","        x = self.dropout(F.relu(self.bn4(self.fc1(x))))\n","        return self.fc2(x)"],"metadata":{"id":"8a0sjnAH7NmM","executionInfo":{"status":"ok","timestamp":1764618057749,"user_tz":360,"elapsed":24,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["model_a = VoiceCNN_Old().to(device)\n","if os.path.exists(MODEL_A_PATH):\n","    model_a.load_state_dict(torch.load(MODEL_A_PATH, map_location=device))\n","    model_a.eval()\n","    print(\"Model A (Baseline) Loaded\")\n","else: print(\"Model A NOT FOUND\")\n","\n","model_b = AgeCNN_New().to(device)\n","if os.path.exists(MODEL_B_PATH):\n","    model_b.load_state_dict(torch.load(MODEL_B_PATH, map_location=device))\n","    model_b.eval()\n","    print(\"Model B (Big Data) Loaded\")\n","else: print(\"Model B NOT FOUND\")\n","\n","model_c = VoiceCNN_Old().to(device)\n","if os.path.exists(MODEL_C_PATH):\n","    model_c.load_state_dict(torch.load(MODEL_C_PATH, map_location=device))\n","    model_c.eval()\n","    print(\"Model C (Augmented) Loaded\")\n","else: print(\"Model C NOT FOUND\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mX7lnCWf7hYJ","executionInfo":{"status":"ok","timestamp":1764618061304,"user_tz":360,"elapsed":904,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}},"outputId":"f7b428e9-a330-45a9-9f6a-e7294f1b873c"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Model A (Baseline) Loaded\n","Model B (Big Data) Loaded\n","Model C (Augmented) Loaded\n"]}]},{"cell_type":"code","source":["# --- 5. Updated Prediction Logic (Full Confidence Breakdown) ---\n","def predict_all():\n","    print(\"\\nðŸ“‚ Click below to upload your voice clip (MP3/WAV)...\")\n","    uploaded = files.upload()\n","\n","    # Define labels locally to ensure they exist\n","    AGE_LABELS_LIST = ['Teens', 'Twenties', 'Thirties', 'Fourties', '50 Plus']\n","    GENDER_LABELS_LIST = ['Female', 'Male']\n","\n","    for filename in uploaded.keys():\n","        print(f\"\\n Processing {filename}...\")\n","        try:\n","            # 1. Process Audio\n","            audio, sr = librosa.load(filename, sr=SAMPLE_RATE, duration=DURATION)\n","            if len(audio) < FIXED_LENGTH:\n","                audio = np.pad(audio, (0, FIXED_LENGTH - len(audio)), 'constant')\n","            else:\n","                audio = audio[:FIXED_LENGTH]\n","\n","            spec = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH)\n","            log_spec = librosa.power_to_db(spec, ref=np.max)\n","            norm_spec = (log_spec - GLOBAL_MEAN) / GLOBAL_STD\n","\n","            tensor = torch.tensor(norm_spec, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n","\n","            # 2. Run Inference\n","            with torch.no_grad():\n","                # Model A\n","                age_logits_a, gender_logits_a = model_a(tensor)\n","                # Model B\n","                age_logits_b = model_b(tensor)\n","                # Model C\n","                age_logits_c, _ = model_c(tensor)\n","\n","            # 3. Decode Results\n","\n","            # -- Gender (From Model A) --\n","            g_probs = torch.softmax(gender_logits_a, dim=1).cpu().numpy()[0]\n","            gender_idx = np.argmax(g_probs)\n","            gender_pred = GENDER_LABELS_LIST[gender_idx]\n","            gender_conf = g_probs[gender_idx] * 100\n","\n","            # -- Age Processing Helper --\n","            def get_age_distribution(logits, is_old_arch=False):\n","                probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n","                if is_old_arch:\n","                    # Map 6 -> 5 classes (Sum 50s + 60s)\n","                    p_50plus = probs[4] + probs[5]\n","                    probs_5 = np.array([probs[0], probs[1], probs[2], probs[3], p_50plus])\n","                else:\n","                    probs_5 = probs\n","                return probs_5 * 100 # Return array of percentages\n","\n","            # Get full distributions\n","            dist_a = get_age_distribution(age_logits_a, is_old_arch=True)\n","            dist_b = get_age_distribution(age_logits_b, is_old_arch=False)\n","            dist_c = get_age_distribution(age_logits_c, is_old_arch=True)\n","\n","            # 4. Print Report\n","            print(\"\\n\" + \"=\"*40)\n","            print(f\"VOICE ANALYSIS REPORT\")\n","            print(\"=\"*40)\n","\n","            # Gender Section\n","            bar_len = int(gender_conf / 5)\n","            g_bar = \"|\" + \"â–ˆ\" * bar_len + \" \" * (20 - bar_len) + \"|\"\n","            print(f\"GENDER DETECTION (Model A)\")\n","            print(f\"   Result: {gender_pred.upper()}\")\n","            print(f\"   Confidence: {g_bar} {gender_conf:.1f}%\")\n","            print(\"-\" * 40)\n","\n","            # Age Section\n","            print(f\"AGE CONFIDENCE BREAKDOWN\")\n","\n","            def print_model_stats(name, distribution):\n","                print(f\"\\n{name}\")\n","                # Find Winner\n","                winner_idx = np.argmax(distribution)\n","                print(f\"   Winner: {AGE_LABELS_LIST[winner_idx].upper()} ({distribution[winner_idx]:.1f}%)\")\n","\n","                # Print Bars\n","                for i, prob in enumerate(distribution):\n","                    bar_len = int(prob / 5)\n","                    bar = \"|\" + \"â–ˆ\" * bar_len + \" \" * (20 - bar_len) + \"|\"\n","                    print(f\"   {AGE_LABELS_LIST[i]:<10} {bar} {prob:.1f}%\")\n","\n","            print_model_stats(\"1. Model A (Baseline)\", dist_a)\n","            print_model_stats(\"2. Model B (Big Data - Recommended)\", dist_b)\n","            print_model_stats(\"3. Model C (Augmented)\", dist_c)\n","\n","            print(\"=\"*40)\n","\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","\n"],"metadata":{"id":"uKsrSDlm7log","executionInfo":{"status":"ok","timestamp":1764618062732,"user_tz":360,"elapsed":13,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["predict_all()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":732},"id":"uK-DIfhI700p","executionInfo":{"status":"ok","timestamp":1764618076864,"user_tz":360,"elapsed":7692,"user":{"displayName":"Vamsi R","userId":"00102015489704140573"}},"outputId":"95853ea0-282e-4386-d4a2-b9d5daa9a27e"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“‚ Click below to upload your voice clip (MP3/WAV)...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a3afe7b7-5782-4c92-b904-db88f6c9973b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a3afe7b7-5782-4c92-b904-db88f6c9973b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving professor.mp3 to professor (5).mp3\n","\n"," Processing professor (5).mp3...\n","\n","========================================\n","VOICE ANALYSIS REPORT\n","========================================\n","GENDER DETECTION (Model A)\n","   Result: MALE\n","   Confidence: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 85.1%\n","----------------------------------------\n","AGE CONFIDENCE BREAKDOWN\n","\n","1. Model A (Baseline)\n","   Winner: FOURTIES (53.6%)\n","   Teens      |â–ˆâ–ˆâ–ˆ                 | 18.8%\n","   Twenties   |â–ˆâ–ˆâ–ˆ                 | 17.5%\n","   Thirties   |                    | 4.6%\n","   Fourties   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 53.6%\n","   50 Plus    |â–ˆ                   | 5.5%\n","\n","2. Model B (Big Data - Recommended)\n","   Winner: TWENTIES (99.3%)\n","   Teens      |                    | 0.3%\n","   Twenties   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 99.3%\n","   Thirties   |                    | 0.4%\n","   Fourties   |                    | 0.0%\n","   50 Plus    |                    | 0.0%\n","\n","3. Model C (Augmented)\n","   Winner: TEENS (45.6%)\n","   Teens      |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 45.6%\n","   Twenties   |â–ˆâ–ˆâ–ˆ                 | 19.6%\n","   Thirties   |â–ˆ                   | 5.6%\n","   Fourties   |â–ˆâ–ˆâ–ˆâ–ˆ                | 21.9%\n","   50 Plus    |â–ˆ                   | 7.3%\n","========================================\n"]}]}]}